{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premade Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:43:42.109552Z",
     "start_time": "2020-03-09T15:43:10.223176Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:44:17.126191Z",
     "start_time": "2020-03-09T15:44:17.121557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:44:34.276277Z",
     "start_time": "2020-03-09T15:44:34.125357Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df = pd.read_csv(\"../data/winequality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:40:28.428763Z",
     "start_time": "2020-02-21T11:40:28.410338Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:44:39.427968Z",
     "start_time": "2020-03-09T15:44:39.414051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# tf doesn't like spaces in col names so I replace them with _ \n",
    "new_col_list = []\n",
    "for col_name in wines_df.columns:\n",
    "    new_col_names = col_name.replace(\" \", \"_\")\n",
    "    new_col_list.append(new_col_names)\n",
    "print(new_col_list)\n",
    "wines_df.columns = new_col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:45:16.744596Z",
     "start_time": "2020-03-09T15:45:16.735587Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining a few helpful constants for parsing the dataset\n",
    "\n",
    "CSV_COLUMN_NAMES = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "QUALITIES = [3, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:45:25.989370Z",
     "start_time": "2020-03-09T15:45:25.986121Z"
    }
   },
   "outputs": [],
   "source": [
    "count_classes = len(QUALITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:54:22.989111Z",
     "start_time": "2020-03-09T15:54:22.979868Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:01:28.613408Z",
     "start_time": "2020-02-21T12:01:28.599065Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "wines_df = wines_df.sample(frac=1) # shuffle data\n",
    "df_dev, test = train_test_split(wines_df, test_size=0.15)\n",
    "train, valid = train_test_split(df_dev, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:01:30.132284Z",
     "start_time": "2020-02-21T12:01:30.087090Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = train.pop('quality')\n",
    "test_y = test.pop('quality')\n",
    "\n",
    "# The target label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:18:02.330421Z",
     "start_time": "2020-02-21T12:18:02.324825Z"
    }
   },
   "outputs": [],
   "source": [
    "train.iloc[0:3,10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:18:31.242673Z",
     "start_time": "2020-02-21T12:18:31.219744Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "\n",
    "data_srs = wines_df.iloc[0,0:-1]\n",
    "\n",
    "my_json = data_srs.to_json()\n",
    "\n",
    "my_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T14:29:40.053275Z",
     "start_time": "2020-02-20T14:29:40.046534Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Create input functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "* features - A Python dictionary in which:\n",
    "    * Each key is the name of a feature.\n",
    "    * Each value is an array containing all of the feature's values.\n",
    "* label - An array containing the values of the label for every example.\n",
    "\n",
    "Just to demonstrate the format of the input function, here's a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:18:49.343291Z",
     "start_time": "2020-02-21T12:18:49.324937Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'fixed_acidity': np.array([6.9, 6.2, 7.1]),\n",
    "                'volatile_acidity': np.array([0.685, 0.58 , 0.43 ]),\n",
    "                'citric_acid': np.array([0.  , 0.  , 0.42]),\n",
    "                'residual_sugar': np.array([2.5, 1.6, 5.5]),\n",
    "                'chlorides': np.array([0.105, 0.065, 0.07]),\n",
    "                'free_sulfur_dioxide': np.array([22.,  8., 29.]),\n",
    "                'total_sulfur_dioxide': np.array([37.,  18., 129.]),\n",
    "                'density': np.array([0.9966, 0.9966, 0.9973]),\n",
    "                'pH': np.array([3.46, 3.56, 3.42]),\n",
    "                'sulphates': np.array([0.57, 0.84, 0.72]),\n",
    "                'alcohol':np.array([10.6,  9.4, 10.5])}\n",
    "    labels = np.array([6, 5, 6])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Your input function may generate the features dictionary and label list any way you like. However, we recommend using TensorFlow's Dataset API, which can parse all sorts of data.\n",
    "\n",
    "The Dataset API can handle a lot of common cases for you. For example, using the Dataset API, you can easily read in records from a large collection of files in parallel and join them into a single stream.\n",
    "\n",
    "To keep things simple in this example you are going to load the data with pandas, and build an input pipeline from this in-memory data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**features (dict)** keys: CSV_COLUMN_NAMES [0:-1] (namely excluding the label of the target variable) , values: np.arrays of the features values \n",
    "\n",
    "**labels (np.array)** the values of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:23:52.603075Z",
     "start_time": "2020-02-21T12:23:52.594690Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T12:19:54.145257Z",
     "start_time": "2020-02-21T12:19:54.120480Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def input_fn(features = CSV_COLUMN_NAMES[0:-1] , labels = QUALITIES, training=True, batch_size=41):\n",
    "    \"\"\" \n",
    "    \n",
    "    An input function for the training and evaluation procedures \n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the inputs to a Dataset. \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "        \n",
    "                                                 \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:05.107396Z",
     "start_time": "2020-02-21T11:34:05.100519Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:07.229157Z",
     "start_time": "2020-02-21T11:34:07.178658Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 6 classes. [3-8]\n",
    "    n_classes=count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train, Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:14.598539Z",
     "start_time": "2020-02-21T11:34:11.990562Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the Model.\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:20.183203Z",
     "start_time": "2020-02-21T11:34:18.876792Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unlike the call to the train method, *you did not pass the steps argument to evaluate*. The input_fn for eval only yields a **single epoch** of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The eval_result dictionary also contains *the average_loss* (mean loss per sample), *the loss* (mean loss per mini-batch) and the value of the *estimator's global_step* (the number of training iterations it underwent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:35.654342Z",
     "start_time": "2020-02-21T11:34:35.649588Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Making predictions (inferring) from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:49:50.280429Z",
     "start_time": "2020-02-21T11:49:50.260207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "predict_x = {\n",
    "    'fixed_acidity': [7.1, 5.6, 0.7],\n",
    "    'volatile_acidity': [0.150, 0.760, 0,352],\n",
    "    'citric_acid': [0.0, 0.25, 0.13],\n",
    "    'residual_sugar': [0.3, 1.5, 2.4],\n",
    "    'chlorides': [0.034, 0.012, 0.056],\n",
    "    'free_sulfur_dioxide': [14.0, 12.0, 15.0],\n",
    "    'total_sulfur_dioxide':[45.0, 12.0, 56.0],\n",
    "    'density':[0.98334, 0.96423, 0.9731],\n",
    "    'pH':[3.12, 3.56, 3.78],\n",
    "    'sulphates':[0.56, 0.75, 0.67],\n",
    "    'alcohol':[12.5, 11.2, 10.3]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:52:11.594298Z",
     "start_time": "2020-02-21T11:52:11.589995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(predictions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The predict method returns a Python iterable, yielding a dictionary of prediction results for each example. The following code prints a few predictions and their probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:49:55.426134Z",
     "start_time": "2020-02-21T11:49:54.923986Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Estimator \n",
    "\n",
    "1. input_func : transforms raw data to Dataset objects.\n",
    "\n",
    "2. feature_func : function that defines the feature cols of the datasets\n",
    "\n",
    "3. model_func : heart of the estimator. This func specifies the type of model used to make predictions and its characteristics e.g DNN with k layers so on and so forth\n",
    "\n",
    "4. train_func, eval_func, test_func : functions relevant to implement the training, evaluation and testing procedures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the options of the estimator to be either a function or a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_estimator(input_func, feat_func, model_func, train_func, valid_func, test_func):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance (why we need an input func in our workflow?)\n",
    "\n",
    "\n",
    "Functionality (what does an input func do?)\n",
    "\n",
    "\n",
    "Implementation (how does the input func do what it is supposed to do?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func(csv) ----> [train_set, valid_set, test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_func():\n",
    "    ...  # manipulate dataset, extracting the feature dict and the label\n",
    "    return feature_dict, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_func(csv_header) ------> (features, target)\n",
    "\n",
    "\n",
    "\n",
    "* We need to define the data type for every attribute column.\n",
    "\n",
    "* We need to normalize each attribute according to its type and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns including their names and type of data they contain.\n",
    "\n",
    "def feature_func(csv_header):\n",
    "\n",
    "    population = tf.feature_column.numeric_column('population')\n",
    "    crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "    median_education = tf.feature_column.numeric_column(\n",
    "        'median_education', normalizer_fn=lambda x: x - global_education_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_func or Model_class? probably the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ) -----> wine.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate an estimator, by passing in the feature columns.\n",
    "\n",
    "\n",
    "def model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ):\n",
    "    # using premade at first then extend it to custom\n",
    "    wine_classifier = \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class BPSomeClass(object):\n",
    "    \"\"\"Brief class description\n",
    "    \n",
    "    Some more extensive description\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    attr1 : string\n",
    "        Purpose of attr1.\n",
    "    attr2 : float\n",
    "        Purpose of attr2.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, param1, param2, param3=0):\n",
    "        \"\"\"Example of docstring on the __init__ method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param1 : str\n",
    "            Description of `param1`.\n",
    "        param2 : float\n",
    "            Description of `param2`.\n",
    "        param3 : int, optional\n",
    "            Description of `param3`, defaults to 0.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.attr1 = param1\n",
    "        self.attr2 = param2\n",
    "        print(param3 // 4)\n",
    "    \n",
    "    @property\n",
    "    def attribute2(self):\n",
    "        return self.attr2\n",
    "    \n",
    "    @attribute2.setter\n",
    "    def attribute2(self, new_attr2):\n",
    "        if not isinstance(float, new_attr2):\n",
    "            raise ValueError(\"attribute2 must be a float, not {0}\".format(new_attr2))\n",
    "        self.attr2 = new_attr2\n",
    "\n",
    "\n",
    "bp_obj = BPSomeClass(\"a\", 1.618)\n",
    "print(bp_obj.attribute2)\n",
    "bp_obj.attribute2 = 3.236\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine.Classifier Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# `input_fn` is the function created in Step 1\n",
    "\n",
    "def train_func(arg):\n",
    "    estimator.train(input_func=train_set, steps=2000)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## val_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_func(arg):\n",
    "    estimator.eval(input_func=eval_set, .....)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_func(arg):\n",
    "    estimator.test(input_func=test_set, .....)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Synthetica)",
   "language": "python",
   "name": "synthetica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
