{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Valid, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:33:04.547011Z",
     "start_time": "2020-02-21T11:33:02.362473Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:33:06.393512Z",
     "start_time": "2020-02-21T11:33:06.382672Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df = pd.read_csv(\"../data/winequality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:33:07.354931Z",
     "start_time": "2020-02-21T11:33:07.347897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# tf doesn't like spaces in col names so I replace them with _ \n",
    "new_col_list = []\n",
    "for col_name in wines_df.columns:\n",
    "    new_col_names = col_name.replace(\" \", \"_\")\n",
    "    new_col_list.append(new_col_names)\n",
    "print(new_col_list)\n",
    "wines_df.columns = new_col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T14:41:12.733304Z",
     "start_time": "2020-02-20T14:41:12.729907Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:31:24.406969Z",
     "start_time": "2020-02-21T11:31:24.210586Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:31:24.505100Z",
     "start_time": "2020-02-21T11:31:24.410399Z"
    }
   },
   "outputs": [],
   "source": [
    "attributes = list(wines_df.columns)\n",
    "feature_labels = attributes[0:-2]\n",
    "target_label = attributes[-1]\n",
    "target_values = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:31:24.595665Z",
     "start_time": "2020-02-21T11:31:24.508138Z"
    }
   },
   "outputs": [],
   "source": [
    "count_classes = len(target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:12.917925Z",
     "start_time": "2020-02-21T11:32:12.882391Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "wines_df = wines_df.sample(frac=1) # shuffle data\n",
    "df_dev, test = train_test_split(wines_df, test_size=0.15)\n",
    "train, valid = train_test_split(df_dev, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:14.699561Z",
     "start_time": "2020-02-21T11:32:14.653282Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = train.pop('quality')\n",
    "test_y = test.pop('quality')\n",
    "\n",
    "# The target label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T14:29:40.053275Z",
     "start_time": "2020-02-20T14:29:40.046534Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:17.599789Z",
     "start_time": "2020-02-21T11:32:17.590575Z"
    }
   },
   "outputs": [],
   "source": [
    "def input_fn(features = feature_labels, labels = target_values, training=True, batch_size=41):\n",
    "    \"\"\" \n",
    "    \n",
    "    An input function for the training and evaluation procedures \n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the inputs to a Dataset. \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "        \n",
    "                                                 \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:19.568552Z",
     "start_time": "2020-02-21T11:32:19.563207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:22.278252Z",
     "start_time": "2020-02-21T11:32:21.745869Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 6 classes. [3-8]\n",
    "    n_classes=count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:28.740403Z",
     "start_time": "2020-02-21T11:32:25.076929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the Model.\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:32:35.696911Z",
     "start_time": "2020-02-21T11:32:34.210713Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the call to the train method, *you did not pass the steps argument to evaluate*. The input_fn for eval only yields a **single epoch** of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval_result dictionary also contains the average_loss (mean loss per sample), the loss (mean loss per mini-batch) and the value of the estimator's global_step (the number of training iterations it underwent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Estimator Components\n",
    "\n",
    "1. input_func : transforms raw data to Dataset objects.\n",
    "\n",
    "2. feature_func : function that defines the feature cols of the datasets\n",
    "\n",
    "3. model_func : heart of the estimator. This func specifies the type of model used to make predictions and its characteristics e.g DNN with k layers so on and so forth\n",
    "\n",
    "4. train_func, eval_func, test_func : functions relevant to implement the training, evaluation and testing procedures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the options of the estimator to be either a function or a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_estimator(input_func, feat_func, model_func, train_func, valid_func, test_func):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance (why we need an input func in our workflow?)\n",
    "\n",
    "\n",
    "Functionality (what does an input func do?)\n",
    "\n",
    "\n",
    "Implementation (how does the input func do what it is supposed to do?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func(csv) ----> [train_set, valid_set, test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_func():\n",
    "    ...  # manipulate dataset, extracting the feature dict and the label\n",
    "    return feature_dict, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_func(csv_header) ------> (features, target)\n",
    "\n",
    "\n",
    "\n",
    "* We need to define the data type for every attribute column.\n",
    "\n",
    "* We need to normalize each attribute according to its type and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns including their names and type of data they contain.\n",
    "\n",
    "def feature_func(csv_header):\n",
    "\n",
    "    population = tf.feature_column.numeric_column('population')\n",
    "    crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "    median_education = tf.feature_column.numeric_column(\n",
    "        'median_education', normalizer_fn=lambda x: x - global_education_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_func or Model_class? probably the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ) -----> wine.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate an estimator, by passing in the feature columns.\n",
    "\n",
    "\n",
    "def model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ):\n",
    "    # using premade at first then extend it to custom\n",
    "    wine_classifier = \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class BPSomeClass(object):\n",
    "    \"\"\"Brief class description\n",
    "    \n",
    "    Some more extensive description\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    attr1 : string\n",
    "        Purpose of attr1.\n",
    "    attr2 : float\n",
    "        Purpose of attr2.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, param1, param2, param3=0):\n",
    "        \"\"\"Example of docstring on the __init__ method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param1 : str\n",
    "            Description of `param1`.\n",
    "        param2 : float\n",
    "            Description of `param2`.\n",
    "        param3 : int, optional\n",
    "            Description of `param3`, defaults to 0.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.attr1 = param1\n",
    "        self.attr2 = param2\n",
    "        print(param3 // 4)\n",
    "    \n",
    "    @property\n",
    "    def attribute2(self):\n",
    "        return self.attr2\n",
    "    \n",
    "    @attribute2.setter\n",
    "    def attribute2(self, new_attr2):\n",
    "        if not isinstance(float, new_attr2):\n",
    "            raise ValueError(\"attribute2 must be a float, not {0}\".format(new_attr2))\n",
    "        self.attr2 = new_attr2\n",
    "\n",
    "\n",
    "bp_obj = BPSomeClass(\"a\", 1.618)\n",
    "print(bp_obj.attribute2)\n",
    "bp_obj.attribute2 = 3.236\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine.Classifier Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# `input_fn` is the function created in Step 1\n",
    "\n",
    "def train_func(arg):\n",
    "    estimator.train(input_func=train_set, steps=2000)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## val_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_func(arg):\n",
    "    estimator.eval(input_func=eval_set, .....)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_func(arg):\n",
    "    estimator.test(input_func=test_set, .....)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that Split Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that split a dataset to a train set, a validation set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Split Func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow :\n",
    "\n",
    "1. Create a pandas dataframe from the csv containing the data.\n",
    "\n",
    "2. Split the dataframe with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def df_split_func(dataframe):\n",
    "    r\"\"\"\n",
    "    \n",
    "    A function that splits a pd.Dataframe to a train set, a validation set and a test set.\n",
    "    \n",
    "    \"\"\"\n",
    "    if condition:\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train\n",
    "    \n",
    "    elif condition :\n",
    "\n",
    "    return valid\n",
    "    \n",
    "    else condition:\n",
    "\n",
    "    return test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Synthetica)",
   "language": "python",
   "name": "synthetica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
